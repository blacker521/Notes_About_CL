---
typora-root-url: ./
---

# 2021.3.3
## [What Makes for Good Views for Contrastive Learning](https://arxiv.org/pdf/2005.10243.pdf) 
主要对比了几种常见的对比学习，为什么能取得比较好的效果。
在保持与下游任务相关的信息的同时，减少视图之间的MI，才能取得比较好的效果。
数据增强是一种有效减小不同视图之间的MI的一种方法
建立视图不变表示的能力是研究核心
**对比表示学习的最佳视图是依赖于任务的**
如果共享信息小，则学习表示可以对输入的详细信息，并实现对多余变量不变的程度更大。

### 提出了三个定义

1. **Sufficient Encoder **
	![](.\img\c_1001.png)
2. **Minimal Sufficient Encoder. **
	![](.\img\c_1002.png)
3. **Optimal Representation of a Task.**
	![](.\img\c_1003.png)
### 用实验证明了对于下游任务，对比与下游相关的特征的重要性
![](.\img\c_1004.png)
上图表示，对于视图v1中的xt进行数据增强，可以控制两个 view 之间共享的变量，分别共享位置，数字，背景。
![](.\img\c_1005.png)

1. **表示不同view之间共享的信息对下游任务影响很大**
	比如只共享数字的部分，学习到的特征表示会忽略背景和位置信息，因此在有关位置和背景的下游任务中无法取得比较好的效果。其他的也类似。
2. **当共享多个信息时，往往其中一个信息会占主导地位**
	如共享数字和位置时，数字占据了主要地位，可能是因为卷积本来就不对位置敏感。
### 学习分为三个阶段
![](.\img\c_1006.png)
这样会形成一个U型，最高点定义为甜点，我们的目标就是让两个视图的信息能够刚好达到甜点，不多不少，只学到特定的特征。
![](.\img\c_1007.png)
![](.\img\c_1008.png)
![](.\img\c_1009.png)

### 问题
对特定任务要有不用不同两个视图，有没有能够让下游任务都很好的特征？
运用到图上的话主要问题还在怎样对数据增强的问题？
特征学习是一个反U型，在图像上可以用色彩抖动来消除，图上应该怎样做？还是说这种问题解决不了？


## [Contrastive Multi-View Representation Learning on Graphs](http://proceedings.mlr.press/v119/hassani20a/hassani20a.pdf) 
在图上用最大化互信息MI来学习表示，主要延伸GraphInfoMax 和SimSLR，又有孪生网路的结构又用了对比互信息。
最大化从图的不同结构视图编码的表示之间的MI来引入自监督方法来训练图编码器。

### 观点
1. 将视图数量增加到两个以上不会提高性能，就用两个对比就行
2. 通过对比来自一阶邻居的编码和图扩散这两个视图，可以实现最佳性能
3. 跨视图对比节点和图的编码能够取得更好的结果
4. 与分层图池化方法相比，简单的图读出层在两项任务上均具有更好的性能
5. 应用正则化或归一化对性能有负面的影响
### 模型
![](.\img\c_2001.png)
1. 节点级和图级进行多视图表示学习
2. 图扩散用于生成样本图和其他结构视图。样本图是同一图的相关视图，仅应用于图结构，不应用于初始节点。并进行子图采样。
3. 用两个专用的GNN和MLP（共享权重）学习节点级的表示。
4. 池化层和MLP层为读出功能，读出图级表示
5. 鉴别器讲一个视图的节点表示与另一视图的图级表示进行对比学习
### 数据增强
**数据增强可以分为两种：**
1. 对初始节点特征进行操作的特征空间增强，例如，掩盖或添加高斯噪声
2. 通过添加或删除连接性，子采样或使用最短距离或扩散矩阵生成全局视图，对图结构进行操作的结构空间扩充和破坏。
3. 在大多数情况下，将邻接矩阵转换为扩散矩阵并将这两个矩阵视为同一图结构的两个全等视图，即可获得最佳结果。我们推测是因为邻接矩阵和扩散矩阵提供了，图结构的局部和全局视图分别最大化了从这两个视图中获悉的表示形式之间的一致性，从而使模型可以同时对丰富的局部和全局信息进行编码。
**扩散矩阵定义**
![](.\img\c_2002.png)
### 编码器
将每个GCN层中节点表示的总和串联起来，然后将其馈送到单层前馈网络，以使节点表示与图形表示之间的尺寸大小保持一致
![](.\img\c_2003.png)
### 总结
这篇工作不是太好，没有比较好的特点，只是用了两个视角，把图像上的东西搬过来，但是模型还是有些建设性意义的。比较像GCN用在对齐上

## [DEEP GRAPH INFOMAX](https://arxiv.org/abs/1809.10341)

DGI是一种无监督方式学习图结构节点表示的通用方法，依赖于最大化局部表示与相应的全局表示之间的互信息。DGI不依赖于随机游走，因为随机游走以图结构信息为目标，过分强调邻近信息，而且依赖于超参数。
定义的全局是局部信息的拼接
**DGI是DIM在图上的应用**
DIM训练编码器模型，以最大化高级“全局”表示和输入的“局部”（例如图像的补丁）之间的相互信息。 鼓励编码器携带在所有位置都存在的信息类型（因此是全局相关的），例如类别标签的情况。**比卷积捕获的结构更加通用**
对比方法的关键实现细节是如何绘制正样本和负样本。 上面关于无监督图表示学习的先前工作依赖于局部对比损失（强制近端节点具有相似的嵌入）。

**这样对比能学习到远距离的结构相似信息。目标是通过图建立相似节点间的链接**
**学习出一个encoder**

### 模型
1. 通过腐蚀函数对负样本进行采样
2. 通过将输入图传给编码器来获得表示hi（正样本）
3. 通过负样本传给编码器来获得表示hj（负样本）
4. 通过读出函数获得全局的表示（平均正样本的表示）
5. 通过判别器和Loss进行更新
![](.\img\c_2004.png)
![](.\img\c_2005.png)
### 局部特征
![](.\img\c_2006.png)
### 全局特征
![](.\img\c_2007.png)
### 获得负样本表示
![](.\img\c_2008.png)
### 区分正负样本对（判别器）
![](.\img\c_2009.png)
### 总结
这篇论文是DMI在Graph上的一个应用，取得了比较好的效果

## [Learning deep representations by mutual information estimation and maximization](https://arxiv.org/abs/1808.06670) 

通过最大化深度神经网络编码器的输入输之间的互信息来进行无监督的表示学习
**将输入中有关局部性的知识纳入目标，可以显著提高表示形式对下游任务的适用性**
对比学习的鼻祖论文，第一次将MI用作对比损失
由于MINE的问世使得MI能够准确的估算，这也使得通过估算MI来进行计算对比损失较为容易。
**结构信息是非常重要的。利用MI进行表示学习，根据下游任务，最大化表示和输入局部区域之间的平均MI，可以极大地提高例如分类任务的表示质量**
在完整的输入和编码器输出（即全局MI）之间最大化MI通常不足以学习有用的表示
引入了两种新的表示质量度量，一种基于互信息神经估计一种基于神经依赖性度量（NDM）
图1是经典的编码器，把高维的特征编码成低维的向量
![](.\img\c_3001.png)
图2是DMI，高维特征编码成特征图之后压缩成高级特征向量，低级的特征图经过判别器进行打分并和高级特征向量加和
**根据下游任务，在原始的X或者X的子图上进行最大化**
![](.\img\c_3002.png)
最大化本地要素和全局要素之间的相互信息。 首先，我们将图像编码为一个特征图，以反映数据的某些结构方面，例如 空间局部性，我们将这个特征图进一步概括为一个全局特征向量（参见图1）。 然后，我们将该特征向量与每个位置的低级特征图连接起来。 通过附加功能为每个局部-全局对生成一个分数。
# 2020.3.4
## [InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization](https://arxiv.org/abs/1908.01000)
论文研究在无监督和半监督情况下学习整个图的表示（图级）
DGI是节点级的预测
最大化图级表示和不同比例的子结构表示（例如节点，边，三角形）之间的相互信息
图形级表示就对跨不同比例的子结构共享的数据各方面进行编码
分为无监督版InfoGraph和半监督版InfoGraph*